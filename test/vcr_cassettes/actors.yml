---
http_interactions:
- request:
    method: get
    uri: https://api.apify.com/v2/acts/zuzka~instagram-hashtag-scraper
    body:
      encoding: US-ASCII
      string: ''
    headers:
      User-Agent:
      - Faraday v2.7.2
      Authorization:
      - Bearer <TOKEN>
  response:
    status:
      code: 200
      message: OK
    headers:
      date:
      - Thu, 05 Jan 2023 11:25:06 GMT
      content-type:
      - application/json; charset=utf-8
      transfer-encoding:
      - chunked
      connection:
      - keep-alive
      cache-control:
      - no-cache, no-store, must-revalidate
      pragma:
      - no-cache
      expires:
      - '0'
      access-control-allow-origin:
      - "*"
      access-control-allow-headers:
      - User-Agent, Content-Type, X-Apify-Request-Origin
      access-control-allow-methods:
      - GET, PUT, DELETE
      access-control-expose-headers:
      - X-Apify-Pagination-Total, X-Apify-Pagination-Offset, X-Apify-Pagination-Desc,
        X-Apify-Pagination-Count, X-Apify-Pagination-Limit
      referrer-policy:
      - no-referrer
      x-robots-tag:
      - none
      x-ratelimit-limit:
      - '30'
      etag:
      - W/"76d2-Q456BpZnrkuC/SM3CS3ltusJ7gc"
      vary:
      - Accept-Encoding
      content-encoding:
      - gzip
    body:
      encoding: UTF-8
      string: "{\n  \"data\": {\n    \"id\": \"reGe1ST3OBgYZSsZJ\",\n    \"userId\":
        \"Zji7Rt6MKGCn6Ae6A\",\n    \"name\": \"instagram-hashtag-scraper\",\n    \"username\":
        \"zuzka\",\n    \"description\": \"Scrape Instagram hashtags the fast and
        easy way. Just add one or more hashtags and the scraper will extract posts,
        images, URLs, comments, likes, users, locations, timestamps, and more. Download
        structured data in JSON, CSV, XML, Excel, and HTML to use in applications,
        reports, and spreadsheets.\",\n    \"restartOnError\": false,\n    \"isPublic\":
        true,\n    \"createdAt\": \"2021-11-16T09:08:08.244Z\",\n    \"modifiedAt\":
        \"2022-12-08T14:24:00.487Z\",\n    \"stats\": {\n      \"totalBuilds\": 129,\n
        \     \"totalRuns\": 190622,\n      \"totalUsers\": 3027,\n      \"totalUsers7Days\":
        120,\n      \"totalUsers30Days\": 459,\n      \"totalUsers90Days\": 1177,\n
        \     \"lastRunStartedAt\": \"2023-01-05T11:10:01.187Z\"\n    },\n    \"versions\":
        [\n      {\n        \"versionNumber\": \"0.0\",\n        \"sourceType\": \"GIT_REPO\",\n
        \       \"envVars\": [],\n        \"sourceFiles\": [\n          {\n            \"name\":
        \"Dockerfile\",\n            \"content\": \"# First, specify the base Docker
        image. You can read more about\\n# the available images at https://sdk.apify.com/docs/guides/docker-images\\n#
        You can also use any other image from Docker Hub.\\nFROM apify/actor-node-puppeteer-chrome:16\\n\\n#
        Second, copy just package.json and package-lock.json since those are the only\\n#
        files that affect \\\"npm install\\\" in the next step, to speed up the build.\\nCOPY
        package*.json ./\\n\\n# Install NPM packages, skip optional and development
        dependencies to\\n# keep the image small. Avoid logging too much and print
        the dependency\\n# tree for debugging\\nRUN npm --quiet set progress=false
        \\\\\\n && npm install --only=prod --no-optional \\\\\\n && echo \\\"Installed
        NPM packages:\\\" \\\\\\n && (npm list --all || true) \\\\\\n && echo \\\"Node.js
        version:\\\" \\\\\\n && node --version \\\\\\n && echo \\\"NPM version:\\\"
        \\\\\\n && npm --version\\n\\n# Next, copy the remaining files and directories
        with the source code.\\n# Since we do this after NPM install, quick build
        will be really fast\\n# for most source file changes.\\nCOPY . ./\\n\\nENV
        APIFY_DISABLE_OUTDATED_WARNING 1\\nENV npm_config_loglevel=silent\\n\\n# Optionally,
        specify how to launch the source code of your actor.\\n# By default, Apify's
        base Docker images define the CMD instruction\\n# that runs the Node.js source
        code using the command specified\\n# in the \\\"scripts.start\\\" section
        of the package.json file.\\n# In short, the instruction looks something like
        this:\\n#\\n# CMD npm start\\n\\n\",\n            \"format\": \"TEXT\"\n          },\n
        \         {\n            \"name\": \"INPUT_SCHEMA.json\",\n            \"content\":
        \"{\\r\\n    \\\"title\\\": \\\"Input schema for Instagram hashtag scraper\\\",\\r\\n
        \   \\\"description\\\": \\\"Set up Instagram hashtag scraper to get posts
        from you hashtag search. <br/> Get data from Instagram profiles <br/> <strong>Important:
        This scraper doesn't extract emails or any other contact details!</strong>
        <br/>\\\",\\r\\n    \\\"type\\\": \\\"object\\\",\\r\\n    \\\"schemaVersion\\\":
        1,\\r\\n    \\\"properties\\\": {\\r\\n        \\\"hashtags\\\": {\\r\\n            \\\"title\\\":
        \\\"Hashtags\\\",\\r\\n            \\\"type\\\": \\\"array\\\",\\r\\n            \\\"description\\\":
        \\\"Provide a hashtag for your search, doesn't matter if you use the # symbol
        or not.\\\",\\r\\n            \\\"editor\\\": \\\"stringList\\\",\\r\\n            \\\"prefill\\\":
        [\\\"webscraping\\\"]\\r\\n        },\\r\\n        \\\"resultsLimit\\\": {\\r\\n
        \           \\\"title\\\": \\\"Maximum posts\\\",\\r\\n            \\\"type\\\":
        \\\"integer\\\",\\r\\n            \\\"description\\\": \\\"How many posts
        you want to maximally scrape from each hashtag. If you set this to 5, you
        will get 5 posts for each hashtag provided (if you provide 2 hastags you will
        get 10 results altogether.\\\",\\r\\n            \\\"editor\\\": \\\"number\\\",\\r\\n
        \           \\\"unit\\\": \\\"per page\\\",\\r\\n            \\\"prefill\\\":
        20\\r\\n        }\\r\\n    },\\r\\n    \\\"required\\\": [\\\"hashtags\\\"]\\r\\n}\",\n
        \           \"format\": \"TEXT\"\n          },\n          {\n            \"name\":
        \"README.md\",\n            \"content\": \"## Features\\r\\nOur free Instagram
        Hashtag Scraper allows you to scrape full Instagram post data based on hashtag
        searches.\\r\\n\\r\\n**This scraper doesn't extract emails or any other contact
        details!**\\r\\n\\r\\n## Why scrape Instagram hashtags?\\r\\nGetting live
        Instagram hashtag data can give you valuable brand or business insights, help
        you predict trends, keep an eye on your competitors, and connect with your
        fans or customers.\\r\\n\\r\\nScraping Instagram hashtags is the fastest,
        most efficient way to get datasets that you can use anywhere.\\r\\n\\r\\nIf
        you want more ideas, check out our [industries pages](https://apify.com/industries)
        for ways web scraping is already being used in a wide range of companies.\\r\\n\\r\\n##
        How to scrape Instagram hashtags\\r\\nIt's super simple to use Instagram Hashtag
        Scraper.\\r\\n1. [Create](https://console.apify.com/sign-up) a free Apify
        account.\\r\\n2. Open [Instagram Hashtag Scraper](https://apify.com/zuzka/instagram-hashtag-scraper)\\r\\n3.
        Add one or more hashtags to scrape.  \\r\\n4. Click run and wait for the datasets
        to be extracted.\\r\\n5. Download your data in JSON, XML, CSV, Excel, or HTML.\\r\\n\\r\\nIf
        you need some hashtag inspiration, here are some Instagram hashtags that regularly
        feature in the top 10:\\r\\n1. #love\\r\\n2. #instagood\\r\\n3. #fashion\\r\\n4.
        #photooftheday\\r\\n5. #beautiful\\r\\n6. #art\\r\\n7. #photography\\r\\n8.
        #happy\\r\\n9. #picoftheday\\r\\n10. #cute\\r\\n\\r\\n## Want to scrape Instagram
        profiles, posts, or comments?\\r\\nUse our super fast and easy dedicated scrapers
        if you want to scrape specific Instagram data. Fewer settings to change and
        faster results. Just enter one or more Instagram usernames or URLs and click
        to scrape.\\r\\n\\r\\n- [Instagram Profile Scraper](https://apify.com/zuzka/instagram-profile-scraper)\\r\\n-
        [Instagram Post Scraper](https://apify.com/zuzka/instagram-post-scraper)\\r\\n-
        [Instagram Comment Scraper](https://apify.com/zuzka/instagram-comment-scraper)\\r\\n\\r\\n##
        Is it legal to scrape Instagram? \\r\\nOur Instagram scrapers are ethical
        and do not extract any private user data, such as email addresses, gender,
        or location. They only extract what the user has chosen to share publicly.
        We therefore believe that our scrapers, when used for ethical purposes by
        Apify users, are safe. However, you should be aware that your results could
        contain personal data. Personal data is protected by the [GDPR](https://en.wikipedia.org/wiki/General_Data_Protection_Regulation)
        in the European Union and by other regulations around the world. You should
        not scrape personal data unless you have a legitimate reason to do so. If
        you're unsure whether your reason is legitimate, consult your lawyers. You
        can also read our blog post on the [legality of web scraping](https://blog.apify.com/is-web-scraping-legal/).\\r\\n\\r\\n##
        Need something more advanced?\\r\\nTry our more advanced [Instagram Scraper](https://apify.com/jaroslavhejlek/instagram-scraper)
        if you need more options and are comfortable with changing settings.\\r\\n\\r\\nLet
        us know if you need a [custom Instagram scraping solution](https://apify.com/custom-solutions).\\r\\n\\r\\n##
        Cost of usage\\r\\nThere are two main factors to take into account if you
        want to run one of our Instagram scrapers on the Apify platform:\\r\\n- [Compute
        units](https://apify.com/pricing/actors) - used for running the scraper\\r\\n-
        [Residential proxy traffic](https://apify.com/pricing/proxy) - needed to access
        Instagram without login\\r\\n\\r\\n### Using proxies\\r\\nInstagram now aggressively
        blocks scrapers and redirects them to a login page. The only reliable solution
        to this problem is to use residential proxies. Datacenter proxies only work
        in rare cases.\\r\\n\\r\\n### Residential proxies\\r\\nInstagram scraper is
        free to use, although you will need to use [residential proxies](https://apify.com/proxy?pricing=residential-ip#pricing)
        on [Apify Proxy](https://apify.com/proxy) if you run it on the Apify platform.
        This is because Instagram changed the rules in 2021 and now you always need
        to use a residential proxy for scraping. Luckily, every new Apify account
        includes a small free trial of residential proxies, so you should be able
        to test any of our Instagram scrapers.\\r\\n\\r\\n### Custom proxies\\r\\nYou
        can also use proxies from other providers in the custom proxies fields (`proxyUrls`
        in the JSON settings).\\r\\n\\r\\n### Cost of usage breakdown\\r\\nScraping
        1,000 Instagram posts will cost you just $4.25 platform credits from your
        [Apify subscription plan](https://apify.com/pricing).\\r\\n\\r\\nScraping
        **1,000 posts** requires about:\\r\\n- **5 compute units**\\r\\n- **0.24 GB
        of proxy traffic**\\r\\n\\r\\n### Example pricing\\r\\nBased on Apify's pricing
        at the time of writing, scraping **1,000 posts** would cost 5 CU * $0.25 +
        0.24 GB * 12.5 GB, which is a total of **$4.25**. The Apify Personal plan
        ($49) would allow you to scrape about 11,500 Instagram posts monthly.\\r\\n\\r\\n##
        Input parameters\\r\\nThe input of this scraper should be JSON containing
        the hashtag or list of hashtags that should be visited. Required fields are:\\r\\n\\r\\n|
        Field | Type | Description |\\r\\n| ----- | ---- | ----------- |\\r\\n| hashtags
        | Array | (required) Hashtags to search on Instagram |\\r\\n| resultsLimit
        | Integer | How many posts should be loaded from each hashtag (limit is per
        hashtag) |\\r\\n\\r\\n## Scrolling through large profiles or posts\\r\\nInstagram
        imposes rate limits that will block scrolling if you want to scroll for more
        than 1,000 posts or comments. To work around this issue, the scraper starts
        injecting randomized wait times once you reach 1,000 posts or comments. This
        is configurable by means of the `scrollWaitSecs` input parameter. If you get
        the message that you were rate limited, consider increasing this parameter
        for the specific profile or post.\\r\\n\\r\\n### Instagram hashtag scraper
        input example\\r\\n\\r\\n```jsonc\\r\\n{\\r\\n    \\\"hashtags\\\": [\\\"apify\\\",
        \\\"webscraping\\\"],\\r\\n    \\\"resultsLimit\\\": 100\\r\\n}\\r\\n```\\r\\n\\r\\n##
        During the actor run\\r\\nDuring the run, the actor will output messages letting
        you know what's going on. Each message always contains a short label specifying
        which page from the provided list is currently being scraped. When items are
        loaded from the page, you should see a message about this event with a loaded
        item count and total item count for each page, in most cases.\\r\\n\\r\\nIf
        you provide incorrect input to the actor, it will immediately stop with a
        failure state and output an explanation of what is wrong.\\r\\n\\r\\n## Instagram
        output format\\r\\nThe actor stores its results in a dataset. Each item is
        a separate item in the dataset.\\r\\n\\r\\nYou can manage the results in any
        language (Python, PHP, Node.js/NPM). See the [Apify API docs](https://docs.apify.com/api/v2)
        to learn more about getting results.\\r\\n\\r\\nThe structure of each item
        in Instagram posts when scrolling looks like this:\\r\\n\\r\\n```jsonc\\r\\n{\\r\\n\\\"queryTag\\\":
        \\\"apify\\\",\\r\\n\\\"position\\\": 5,\\r\\n\\\"type\\\": \\\"Image\\\",\\r\\n\\\"shortCode\\\":
        \\\"CPX3fh-sCAu\\\",\\r\\n\\\"caption\\\": \\\"SEO GRILL MASTER\U0001F969\U0001F525\\\\n•\\\\n•\\\\n#startuplife
        #apify #teambuilding\\\",\\r\\n\\\"hashtags\\\": [\\r\\n\\\"startuplife\\\",\\r\\n\\\"apify\\\",\\r\\n\\\"teambuilding\\\"\\r\\n],\\r\\n\\\"mentions\\\":
        [],\\r\\n\\\"url\\\": \\\"https://www.instagram.com/p/CPX3fh-sCAu\\\",\\r\\n\\\"commentsCount\\\":
        0,\\r\\n\\\"latestComments\\\": [],\\r\\n\\\"dimensionsHeight\\\": 1080,\\r\\n\\\"dimensionsWidth\\\":
        1080,\\r\\n\\\"displayUrl\\\": \\\"https://scontent-iev1-1.cdninstagram.com/v/t51.2885-15/e35/s1080x1080/191303163_3815835068538270_8324023149941865199_n.jpg?_nc_ht=scontent-iev1-1.cdninstagram.com&_nc_cat=106&_nc_ohc=exAwEYfHv2AAX8Wv4L_&edm=ABZsPhsBAAAA&ccb=7-4&oh=c785300c3ce8c893579c0be6bc418513&oe=61A4054C&_nc_sid=4efc9f\\\",\\r\\n\\\"images\\\":
        [],\\r\\n\\\"id\\\": \\\"2582776970667368494\\\",\\r\\n\\\"alt\\\": \\\"Photo
        by Apify in Přístav 18600. May be an image of one or more people and outdoors.\\\",\\r\\n\\\"likesCount\\\":
        6,\\r\\n\\\"timestamp\\\": \\\"2021-05-27T10:23:49.000Z\\\",\\r\\n\\\"locationName\\\":
        null,\\r\\n\\\"locationId\\\": null,\\r\\n\\\"ownerUsername\\\": \\\"apifytech\\\",\\r\\n\\\"ownerId\\\":
        \\\"29230178602\\\",\\r\\n\\\"fullName\\\": \\\"Apify\\\"\\r\\n},\\r\\n```\\r\\n##
        Personal data\\r\\nYou should be aware that your results could contain personal
        data. Personal data is protected by GDPR in the European Union and by other
        regulations around the world. You should not scrape personal data unless you
        have a legitimate reason to do so. If you're unsure whether your reason is
        legitimate, consult your lawyers. You can also read our blog post on the [legality
        of web scraping](https://blog.apify.com/is-web-scraping-legal/).\",\n            \"format\":
        \"TEXT\"\n          },\n          {\n            \"name\": \"main.js\",\n
        \           \"content\": \"import Apify from 'apify';\\r\\n\\r\\nApify.main(async
        () => {\\r\\n    const input = await Apify.getInput();\\r\\n    let directUrls
        = [];\\r\\n    for (const h in input.hashtags) {\\r\\n        if (input.hashtags[h].toLowerCase().includes('instagram.com/explore/tags/'))
        {\\r\\n            directUrls.push(input.hashtags[h])    \\r\\n        } else
        if (input.hashtags[h].toLowerCase().includes('instagram.com/')) {\\r\\n            Apify.utils.log.warning(`Sorry,
        ${input.hashtags[h]} is not a valid input, skipping. Use hashtag or instagram
        hashtag URL containing \\\"instagram.com/explore/tags/\\\"`)\\r\\n        }
        else {\\r\\n            let hashtag = input.hashtags[h];\\r\\n            if
        (hashtag.startsWith(\\\"#\\\")) {\\r\\n                hashtag = hashtag.replace(\\\"#\\\",
        \\\"\\\");\\r\\n            }\\r\\n            const directUrl = `https://www.instagram.com/explore/tags/${hashtag}`;\\r\\n
        \           directUrls.push(directUrl);\\r\\n        }\\r\\n    }\\r\\n\\r\\n
        \   const extendOutputFunction = async ({ data, item, itemSpec, page, request,
        customData, label }) => {\\r\\n        item.fullName = item.owner && item.owner.full_name
        ? item.owner.full_name : 'owner didnt open';\\r\\n        if (item.owner)
        { delete item.owner; }\\r\\n        return item;\\r\\n    }\\r\\n\\r\\n    await
        Apify.metamorph('jaroslavhejlek/instagram-scraper', {\\r\\n        ...input,\\r\\n
        \       resultsType: \\\"posts\\\",\\r\\n        searchType:  \\\"hashtag\\\",\\r\\n
        \       searchLimit: 1,\\r\\n        expandOwners: true,\\r\\n        proxy:
        {\\r\\n            \\\"useApifyProxy\\\": true,\\r\\n            \\\"apifyProxyGroups\\\":
        [\\\"RESIDENTIAL\\\"]\\r\\n        },\\r\\n        directUrls,\\r\\n        extendOutputFunction:
        extendOutputFunction.toString(),\\r\\n    });\\r\\n});\",\n            \"format\":
        \"TEXT\"\n          },\n          {\n            \"name\": \"package.json\",\n
        \           \"content\": \"{\\r\\n    \\\"name\\\": \\\"Instagram-hashtag-scraper\\\",\\r\\n
        \   \\\"version\\\": \\\"0.0.1\\\",\\r\\n    \\\"type\\\": \\\"module\\\",\\r\\n
        \   \\\"dependencies\\\": {\\r\\n        \\\"apify\\\": \\\"^2.1.0\\\"\\r\\n
        \   },\\r\\n    \\\"scripts\\\": {\\r\\n        \\\"start\\\": \\\"node main.js\\\"\\r\\n
        \   }\\r\\n}\\r\\n\",\n            \"format\": \"TEXT\"\n          }\n        ],\n
        \       \"applyEnvVarsToBuild\": false,\n        \"buildTag\": \"latest\",\n
        \       \"gitRepoUrl\": \"git@github.com:apify-projects/store-instagram-miniactors.git#main:instagram-hashtag\"\n
        \     },\n      {\n        \"versionNumber\": \"0.1\",\n        \"sourceType\":
        \"GIT_REPO\",\n        \"envVars\": [],\n        \"sourceFiles\": [\n          {\n
        \           \"name\": \"Dockerfile\",\n            \"content\": \"# First,
        specify the base Docker image. You can read more about\\n# the available images
        at https://sdk.apify.com/docs/guides/docker-images\\n# You can also use any
        other image from Docker Hub.\\nFROM apify/actor-node-puppeteer-chrome:16\\n\\n#
        Second, copy just package.json and package-lock.json since those are the only\\n#
        files that affect \\\"npm install\\\" in the next step, to speed up the build.\\nCOPY
        package*.json ./\\n\\n# Install NPM packages, skip optional and development
        dependencies to\\n# keep the image small. Avoid logging too much and print
        the dependency\\n# tree for debugging\\nRUN npm --quiet set progress=false
        \\\\\\n && npm install --only=prod --no-optional \\\\\\n && echo \\\"Installed
        NPM packages:\\\" \\\\\\n && (npm list --all || true) \\\\\\n && echo \\\"Node.js
        version:\\\" \\\\\\n && node --version \\\\\\n && echo \\\"NPM version:\\\"
        \\\\\\n && npm --version\\n\\n# Next, copy the remaining files and directories
        with the source code.\\n# Since we do this after NPM install, quick build
        will be really fast\\n# for most source file changes.\\nCOPY . ./\\n\\nENV
        APIFY_DISABLE_OUTDATED_WARNING 1\\nENV npm_config_loglevel=silent\\n\\n# Optionally,
        specify how to launch the source code of your actor.\\n# By default, Apify's
        base Docker images define the CMD instruction\\n# that runs the Node.js source
        code using the command specified\\n# in the \\\"scripts.start\\\" section
        of the package.json file.\\n# In short, the instruction looks something like
        this:\\n#\\n# CMD npm start\\n\\n\",\n            \"format\": \"TEXT\"\n          },\n
        \         {\n            \"name\": \"INPUT_SCHEMA.json\",\n            \"content\":
        \"{\\r\\n    \\\"title\\\": \\\"Input schema for Instagram hashtag scraper\\\",\\r\\n
        \   \\\"description\\\": \\\"Set up Instagram hashtag scraper to get posts
        from you hashtag search. <br/> Get data from Instagram profiles <br/> <strong>Important:
        This scraper doesn't extract emails or any other contact details!</strong>
        <br/>\\\",\\r\\n    \\\"type\\\": \\\"object\\\",\\r\\n    \\\"schemaVersion\\\":
        1,\\r\\n    \\\"properties\\\": {\\r\\n        \\\"hashtags\\\": {\\r\\n            \\\"title\\\":
        \\\"Hashtags\\\",\\r\\n            \\\"type\\\": \\\"array\\\",\\r\\n            \\\"description\\\":
        \\\"Provide a hashtag for your search, doesn't matter if you use the # symbol
        or not.\\\",\\r\\n            \\\"editor\\\": \\\"stringList\\\",\\r\\n            \\\"prefill\\\":
        [\\\"webscraping\\\"]\\r\\n        },\\r\\n        \\\"resultsLimit\\\": {\\r\\n
        \           \\\"title\\\": \\\"Maximum posts\\\",\\r\\n            \\\"type\\\":
        \\\"integer\\\",\\r\\n            \\\"description\\\": \\\"How many posts
        you want to maximally scrape from each hashtag. If you set this to 5, you
        will get 5 posts for each hashtag provided (if you provide 2 hastags you will
        get 10 results altogether.\\\",\\r\\n            \\\"editor\\\": \\\"number\\\",\\r\\n
        \           \\\"unit\\\": \\\"per page\\\",\\r\\n            \\\"prefill\\\":
        20\\r\\n        }\\r\\n    },\\r\\n    \\\"required\\\": [\\\"hashtags\\\"]\\r\\n}\",\n
        \           \"format\": \"TEXT\"\n          },\n          {\n            \"name\":
        \"README.md\",\n            \"content\": \"## Features\\r\\nOur free Instagram
        Hashtag Scraper allows you to scrape full Instagram post data based on hashtag
        searches.\\r\\n\\r\\n**This scraper doesn't extract emails or any other contact
        details!**\\r\\n\\r\\n## Why scrape Instagram hashtags?\\r\\nGetting live
        Instagram hashtag data can give you valuable brand or business insights, help
        you predict trends, keep an eye on your competitors, and connect with your
        fans or customers.\\r\\n\\r\\nScraping Instagram hashtags is the fastest,
        most efficient way to get datasets that you can use anywhere.\\r\\n\\r\\nIf
        you want more ideas, check out our [industries pages](https://apify.com/industries)
        for ways web scraping is already being used in a wide range of companies.\\r\\n\\r\\n##
        How to scrape Instagram hashtags\\r\\nIt's super simple to use Instagram Hashtag
        Scraper.\\r\\n1. [Create](https://console.apify.com/sign-up) a free Apify
        account.\\r\\n2. Open [Instagram Hashtag Scraper](https://apify.com/zuzka/instagram-hashtag-scraper)\\r\\n3.
        Add one or more hashtags to scrape.  \\r\\n4. Click run and wait for the datasets
        to be extracted.\\r\\n5. Download your data in JSON, XML, CSV, Excel, or HTML.\\r\\n\\r\\nIf
        you need some hashtag inspiration, here are some Instagram hashtags that regularly
        feature in the top 10:\\r\\n1. #love\\r\\n2. #instagood\\r\\n3. #fashion\\r\\n4.
        #photooftheday\\r\\n5. #beautiful\\r\\n6. #art\\r\\n7. #photography\\r\\n8.
        #happy\\r\\n9. #picoftheday\\r\\n10. #cute\\r\\n\\r\\n## Want to scrape Instagram
        profiles, posts, or comments?\\r\\nUse our super fast and easy dedicated scrapers
        if you want to scrape specific Instagram data. Fewer settings to change and
        faster results. Just enter one or more Instagram usernames or URLs and click
        to scrape.\\r\\n\\r\\n- [Instagram Profile Scraper](https://apify.com/zuzka/instagram-profile-scraper)\\r\\n-
        [Instagram Post Scraper](https://apify.com/zuzka/instagram-post-scraper)\\r\\n-
        [Instagram Comment Scraper](https://apify.com/zuzka/instagram-comment-scraper)\\r\\n\\r\\n##
        Is it legal to scrape Instagram? \\r\\nOur Instagram scrapers are ethical
        and do not extract any private user data, such as email addresses, gender,
        or location. They only extract what the user has chosen to share publicly.
        We therefore believe that our scrapers, when used for ethical purposes by
        Apify users, are safe. However, you should be aware that your results could
        contain personal data. Personal data is protected by the [GDPR](https://en.wikipedia.org/wiki/General_Data_Protection_Regulation)
        in the European Union and by other regulations around the world. You should
        not scrape personal data unless you have a legitimate reason to do so. If
        you're unsure whether your reason is legitimate, consult your lawyers. You
        can also read our blog post on the [legality of web scraping](https://blog.apify.com/is-web-scraping-legal/).\\r\\n\\r\\n##
        Need something more advanced?\\r\\nTry our more advanced [Instagram Scraper](https://apify.com/jaroslavhejlek/instagram-scraper)
        if you need more options and are comfortable with changing settings.\\r\\n\\r\\nLet
        us know if you need a [custom Instagram scraping solution](https://apify.com/custom-solutions).\\r\\n\\r\\n##
        Cost of usage\\r\\nThere are two main factors to take into account if you
        want to run one of our Instagram scrapers on the Apify platform:\\r\\n- [Compute
        units](https://apify.com/pricing/actors) - used for running the scraper\\r\\n-
        [Residential proxy traffic](https://apify.com/pricing/proxy) - needed to access
        Instagram without login\\r\\n\\r\\n### Using proxies\\r\\nInstagram now aggressively
        blocks scrapers and redirects them to a login page. The only reliable solution
        to this problem is to use residential proxies. Datacenter proxies only work
        in rare cases.\\r\\n\\r\\n### Residential proxies\\r\\nInstagram scraper is
        free to use, although you will need to use [residential proxies](https://apify.com/proxy?pricing=residential-ip#pricing)
        on [Apify Proxy](https://apify.com/proxy) if you run it on the Apify platform.
        This is because Instagram changed the rules in 2021 and now you always need
        to use a residential proxy for scraping. Luckily, every new Apify account
        includes a small free trial of residential proxies, so you should be able
        to test any of our Instagram scrapers.\\r\\n\\r\\n### Custom proxies\\r\\nYou
        can also use proxies from other providers in the custom proxies fields (`proxyUrls`
        in the JSON settings).\\r\\n\\r\\n### Cost of usage breakdown\\r\\nScraping
        1,000 Instagram posts will cost you just $4.25 platform credits from your
        [Apify subscription plan](https://apify.com/pricing).\\r\\n\\r\\nScraping
        **1,000 posts** requires about:\\r\\n- **5 compute units**\\r\\n- **0.24 GB
        of proxy traffic**\\r\\n\\r\\n### Example pricing\\r\\nBased on Apify's pricing
        at the time of writing, scraping **1,000 posts** would cost 5 CU * $0.25 +
        0.24 GB * 12.5 GB, which is a total of **$4.25**. The Apify Personal plan
        ($49) would allow you to scrape about 11,500 Instagram posts monthly.\\r\\n\\r\\n##
        Input parameters\\r\\nThe input of this scraper should be JSON containing
        the hashtag or list of hashtags that should be visited. Required fields are:\\r\\n\\r\\n|
        Field | Type | Description |\\r\\n| ----- | ---- | ----------- |\\r\\n| hashtags
        | Array | (required) Hashtags to search on Instagram |\\r\\n| resultsLimit
        | Integer | How many posts should be loaded from each hashtag (limit is per
        hashtag) |\\r\\n\\r\\n## Scrolling through large profiles or posts\\r\\nInstagram
        imposes rate limits that will block scrolling if you want to scroll for more
        than 1,000 posts or comments. To work around this issue, the scraper starts
        injecting randomized wait times once you reach 1,000 posts or comments. This
        is configurable by means of the `scrollWaitSecs` input parameter. If you get
        the message that you were rate limited, consider increasing this parameter
        for the specific profile or post.\\r\\n\\r\\n### Instagram hashtag scraper
        input example\\r\\n\\r\\n```jsonc\\r\\n{\\r\\n    \\\"hashtags\\\": [\\\"apify\\\",
        \\\"webscraping\\\"],\\r\\n    \\\"resultsLimit\\\": 100\\r\\n}\\r\\n```\\r\\n\\r\\n##
        During the actor run\\r\\nDuring the run, the actor will output messages letting
        you know what's going on. Each message always contains a short label specifying
        which page from the provided list is currently being scraped. When items are
        loaded from the page, you should see a message about this event with a loaded
        item count and total item count for each page, in most cases.\\r\\n\\r\\nIf
        you provide incorrect input to the actor, it will immediately stop with a
        failure state and output an explanation of what is wrong.\\r\\n\\r\\n## Instagram
        output format\\r\\nThe actor stores its results in a dataset. Each item is
        a separate item in the dataset.\\r\\n\\r\\nYou can manage the results in any
        language (Python, PHP, Node.js/NPM). See the [Apify API docs](https://docs.apify.com/api/v2)
        to learn more about getting results.\\r\\n\\r\\nThe structure of each item
        in Instagram posts when scrolling looks like this:\\r\\n\\r\\n```jsonc\\r\\n{\\r\\n\\\"queryTag\\\":
        \\\"apify\\\",\\r\\n\\\"position\\\": 5,\\r\\n\\\"type\\\": \\\"Image\\\",\\r\\n\\\"shortCode\\\":
        \\\"CPX3fh-sCAu\\\",\\r\\n\\\"caption\\\": \\\"SEO GRILL MASTER\U0001F969\U0001F525\\\\n•\\\\n•\\\\n#startuplife
        #apify #teambuilding\\\",\\r\\n\\\"hashtags\\\": [\\r\\n\\\"startuplife\\\",\\r\\n\\\"apify\\\",\\r\\n\\\"teambuilding\\\"\\r\\n],\\r\\n\\\"mentions\\\":
        [],\\r\\n\\\"url\\\": \\\"https://www.instagram.com/p/CPX3fh-sCAu\\\",\\r\\n\\\"commentsCount\\\":
        0,\\r\\n\\\"latestComments\\\": [],\\r\\n\\\"dimensionsHeight\\\": 1080,\\r\\n\\\"dimensionsWidth\\\":
        1080,\\r\\n\\\"displayUrl\\\": \\\"https://scontent-iev1-1.cdninstagram.com/v/t51.2885-15/e35/s1080x1080/191303163_3815835068538270_8324023149941865199_n.jpg?_nc_ht=scontent-iev1-1.cdninstagram.com&_nc_cat=106&_nc_ohc=exAwEYfHv2AAX8Wv4L_&edm=ABZsPhsBAAAA&ccb=7-4&oh=c785300c3ce8c893579c0be6bc418513&oe=61A4054C&_nc_sid=4efc9f\\\",\\r\\n\\\"images\\\":
        [],\\r\\n\\\"id\\\": \\\"2582776970667368494\\\",\\r\\n\\\"alt\\\": \\\"Photo
        by Apify in Přístav 18600. May be an image of one or more people and outdoors.\\\",\\r\\n\\\"likesCount\\\":
        6,\\r\\n\\\"timestamp\\\": \\\"2021-05-27T10:23:49.000Z\\\",\\r\\n\\\"locationName\\\":
        null,\\r\\n\\\"locationId\\\": null,\\r\\n\\\"ownerUsername\\\": \\\"apifytech\\\",\\r\\n\\\"ownerId\\\":
        \\\"29230178602\\\",\\r\\n\\\"fullName\\\": \\\"Apify\\\"\\r\\n},\\r\\n```\\r\\n##
        Personal data\\r\\nYou should be aware that your results could contain personal
        data. Personal data is protected by GDPR in the European Union and by other
        regulations around the world. You should not scrape personal data unless you
        have a legitimate reason to do so. If you're unsure whether your reason is
        legitimate, consult your lawyers. You can also read our blog post on the [legality
        of web scraping](https://blog.apify.com/is-web-scraping-legal/).\",\n            \"format\":
        \"TEXT\"\n          },\n          {\n            \"name\": \"main.js\",\n
        \           \"content\": \"import Apify from 'apify';\\r\\n\\r\\nApify.main(async
        () => {\\r\\n    const input = await Apify.getInput();\\r\\n    let directUrls
        = [];\\r\\n    for (const h in input.hashtags) {\\r\\n        if (input.hashtags[h].toLowerCase().includes('instagram.com/explore/tags/'))
        {\\r\\n            directUrls.push(input.hashtags[h])    \\r\\n        } else
        if (input.hashtags[h].toLowerCase().includes('instagram.com/')) {\\r\\n            Apify.utils.log.warning(`Sorry,
        ${input.hashtags[h]} is not a valid input, skipping. Use hashtag or instagram
        hashtag URL containing \\\"instagram.com/explore/tags/\\\"`)\\r\\n        }
        else {\\r\\n            let hashtag = input.hashtags[h];\\r\\n            if
        (hashtag.startsWith(\\\"#\\\")) {\\r\\n                hashtag = hashtag.replace(\\\"#\\\",
        \\\"\\\");\\r\\n            }\\r\\n            const directUrl = `https://www.instagram.com/explore/tags/${hashtag}`;\\r\\n
        \           directUrls.push(directUrl);\\r\\n        }\\r\\n    }\\r\\n\\r\\n
        \   const extendOutputFunction = async ({ data, item, itemSpec, page, request,
        customData, label }) => {\\r\\n        item.fullName = item.owner && item.owner.full_name
        ? item.owner.full_name : 'owner didnt open';\\r\\n        if (item.owner)
        { delete item.owner; }\\r\\n        return item;\\r\\n    }\\r\\n\\r\\n    await
        Apify.metamorph('jaroslavhejlek/instagram-scraper', {\\r\\n        ...input,\\r\\n
        \       resultsType: \\\"posts\\\",\\r\\n        searchType:  \\\"hashtag\\\",\\r\\n
        \       searchLimit: 1,\\r\\n        expandOwners: true,\\r\\n        proxy:
        {\\r\\n            \\\"useApifyProxy\\\": true,\\r\\n            \\\"apifyProxyGroups\\\":
        [\\\"RESIDENTIAL\\\"]\\r\\n        },\\r\\n        directUrls,\\r\\n        extendOutputFunction:
        extendOutputFunction.toString(),\\r\\n    });\\r\\n});\",\n            \"format\":
        \"TEXT\"\n          },\n          {\n            \"name\": \"package.json\",\n
        \           \"content\": \"{\\r\\n    \\\"name\\\": \\\"Instagram-hashtag-scraper\\\",\\r\\n
        \   \\\"version\\\": \\\"0.0.1\\\",\\r\\n    \\\"type\\\": \\\"module\\\",\\r\\n
        \   \\\"dependencies\\\": {\\r\\n        \\\"apify\\\": \\\"^2.1.0\\\"\\r\\n
        \   },\\r\\n    \\\"scripts\\\": {\\r\\n        \\\"start\\\": \\\"node main.js\\\"\\r\\n
        \   }\\r\\n}\\r\\n\",\n            \"format\": \"TEXT\"\n          }\n        ],\n
        \       \"applyEnvVarsToBuild\": false,\n        \"buildTag\": \"beta\",\n
        \       \"gitRepoUrl\": \"git@github.com:apify-projects/store-instagram-miniactors.git#main:instagram-hashtag\"\n
        \     }\n    ],\n    \"defaultRunOptions\": {\n      \"build\": \"latest\",\n
        \     \"timeoutSecs\": 10000,\n      \"memoryMbytes\": 4096\n    },\n    \"exampleRunInput\":
        {\n      \"body\": \"{ \\\"helloWorld\\\": 123 }\",\n      \"contentType\":
        \"application/json; charset=utf-8\"\n    },\n    \"categories\": [\n      \"SOCIAL_MEDIA\"\n
        \   ],\n    \"isDeprecated\": false,\n    \"title\": \"Instagram Hashtag Scraper\",\n
        \   \"pictureUrl\": \"https://apify-image-uploads-prod.s3.amazonaws.com/reGe1ST3OBgYZSsZJ/SG5MzxGFjkBjx4yXS-Insta_hashtag_icon.png\",\n
        \   \"seoTitle\": \"Instagram Hashtag Scraper\",\n    \"seoDescription\":
        \"Want to scrape Instagram hashtags? Scrape one or more hashtags fast. Get
        posts, images, URLs, comments, likes, users, locations, and timestamps.\",\n
        \   \"notice\": \"NONE\",\n    \"isCritical\": true,\n    \"deploymentKey\":
        \"ssh-rsa AAAAB3NzaC1yc2EAAAADAQABAAABAQD3FRdWunyKgcgOsCeCDnvL8SfefW5tVy2yqvS51jeELuwquADN0TFZebnXLHAT9vDMR01lq3yr2Myt43ZEzat8MdzhVkCegxKBr8EdCZIOWzwZOqoSwtGqnvoN4sAkwEI+5Xq6Iohhy68+eyECaXPJCsEAfTEU7rHHWcpTTcVf3q1gtXviLUpFPLpLil21h368N2Pwk6rivGrN9KltLplOM6mdDfPYe2SxNShY0BjPuW0C0g33JT7XVgr771C1D+Q1IRP5OFIlcYzWJLdt8VlsPizavteEnWWhWmWXaUeEPdbCbw6BP9VeFseY079ofQs5qIouLqILada9NPSTnVFL
        \\n\",\n    \"taggedBuilds\": {\n      \"latest\": {\n        \"buildId\":
        \"zgpxzahT8WXe1rsui\",\n        \"buildNumber\": \"0.0.87\",\n        \"finishedAt\":
        \"2022-12-08T14:24:00.487Z\"\n      },\n      \"beta\": {\n        \"buildId\":
        \"cUkjr0876oXNpjgnY\",\n        \"buildNumber\": \"0.1.42\",\n        \"finishedAt\":
        \"2022-12-08T14:22:03.654Z\"\n      }\n    }\n  }\n}"
  recorded_at: Thu, 05 Jan 2023 11:25:06 GMT
recorded_with: VCR 6.1.0
